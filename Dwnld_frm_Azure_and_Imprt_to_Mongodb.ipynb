{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#pip install azure.storage.blob"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "## Successfully uploads to the database with nested structure\r\n",
    "\r\n",
    "# Retrieve list of blobs from designated container\r\n",
    "# Check if blob name is a file name in current directory\r\n",
    "# If no same file name in directory, download the file associated with that blobname\r\n",
    "# If it downloads the file, then it also opens it, restructures the data into a nested format and imports the data to mongodb\r\n",
    "\r\n",
    "import time\r\n",
    "from azure.storage.blob import ContainerClient\r\n",
    "from azure.storage.blob import BlobServiceClient\r\n",
    "import json\r\n",
    "from pymongo import MongoClient\r\n",
    "\r\n",
    "# Define function to build nested json \r\n",
    "def make_nested_json(list_of_json):\r\n",
    "    participant_name = list_of_json[0]['Participant']\r\n",
    "    participant_ID = list_of_json[0]['Participant_ID']\r\n",
    "    session_ID = list_of_json[0]['Session_ID']\r\n",
    "    streams_and_data = [\r\n",
    "        {\r\n",
    "            'stream_type': list_of_json[0]['stream_type'], \r\n",
    "            'data': []\r\n",
    "        }\r\n",
    "    ]\r\n",
    "    for i in range(len(list_of_json)):\r\n",
    "        streams_in_dict = [a_dict[\"stream_type\"] for a_dict in streams_and_data]\r\n",
    "        indexed_stream_type = list_of_json[i]['stream_type']\r\n",
    "        if indexed_stream_type in streams_in_dict:                   \r\n",
    "            pass\r\n",
    "        else:\r\n",
    "            streams_and_data.append(\r\n",
    "                {\r\n",
    "                    'stream_type': indexed_stream_type,\r\n",
    "                    'data': []\r\n",
    "                }\r\n",
    "            )\r\n",
    "        streams_in_dict = [a_dict[\"stream_type\"] for a_dict in streams_and_data]\r\n",
    "        n = streams_in_dict.index(indexed_stream_type)\r\n",
    "        streams_and_data[n]['data'].append(\r\n",
    "            {\r\n",
    "                'Value': list_of_json[i]['Value'],\r\n",
    "                'dateTime': list_of_json[i]['dateTime_Unix']\r\n",
    "            }\r\n",
    "        )\r\n",
    "    nested_json = {\r\n",
    "        'Session_ID': session_ID,\r\n",
    "        'Participant_ID': participant_ID,\r\n",
    "        'Participant': participant_name,\r\n",
    "        'Streams': streams_and_data\r\n",
    "    } \r\n",
    "    return nested_json  \r\n",
    "\r\n",
    "blob_service_client_instance = BlobServiceClient(account_url=STORAGEACCOUNTURL, credential=STORAGEACCOUNTKEY)\r\n",
    "container = ContainerClient.from_connection_string(conn_str=os.environ.get('AZURE_STORAGE_CONNECTION_STRING'), container_name=\"container2\")\r\n",
    "\r\n",
    "new_files = []\r\n",
    "all_files = []\r\n",
    "\r\n",
    "blob_list = container.list_blobs()\r\n",
    "for blob in blob_list:\r\n",
    "    print(blob.name + '\\n')\r\n",
    "    all_files.append(blob.name)\r\n",
    "    if blob.name not in os.listdir(os.curdir):\r\n",
    "        new_files.append(blob.name)\r\n",
    "        t1=time.time()\r\n",
    "        blob_client_instance = blob_service_client_instance.get_blob_client(\"container2\", blob.name, snapshot=None)\r\n",
    "        with open(blob.name, \"wb\") as my_blob:\r\n",
    "            blob_data = blob_client_instance.download_blob()\r\n",
    "            blob_data.readinto(my_blob)\r\n",
    "        t2=time.time()\r\n",
    "        print((\"It takes %s seconds to download \"+blob.name + '\\n') % (t2 - t1))\r\n",
    "\r\n",
    "### Import new data to mongodb, one file at a time\r\n",
    "\r\n",
    "# Making Connection\r\n",
    "myclient = MongoClient(\"mongodb://localhost:27017/\")\r\n",
    "\r\n",
    "# database\r\n",
    "db = myclient[\"Sensorlab\"]  #update here to switch database\r\n",
    "\r\n",
    "# Create or switch to collection\r\n",
    "Collection = db[\"test_nestedJSON\"]  #update here to switch collection\r\n",
    "\r\n",
    "for i in range(len(new_files)):\r\n",
    "    with open(new_files[i]) as f:\r\n",
    "        content = f.readlines()\r\n",
    "    file_data = []\r\n",
    "    for data in content:\r\n",
    "        file_data.append(json.loads(data))\r\n",
    "\r\n",
    "    nested_json_file_data = make_nested_json(file_data)\r\n",
    "\r\n",
    "    if isinstance(nested_json_file_data, list):\r\n",
    "        Collection.insert_many(nested_json_file_data)\r\n",
    "    else:\r\n",
    "        Collection.insert_one(nested_json_file_data)\r\n",
    "\r\n",
    "    print(f\"Imported {new_files[i]} to the database.\")\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0_18fc7328361948c0865df2f0c53aa008_1.json\n",
      "\n",
      "0_2f7120ed65194093a6df6dacd979d706_1.json\n",
      "\n",
      "0_36ecfdb7ea4941c2938e3f91a9003ea0_1.json\n",
      "\n",
      "It takes 2.759887933731079 seconds to download 0_36ecfdb7ea4941c2938e3f91a9003ea0_1.json\n",
      "\n",
      "0_4862fd0f886945c6b5fa1ed9b391e807_1.json\n",
      "\n",
      "0_5e20c79f9efc42fc9c09b4443a6646de_1.json\n",
      "\n",
      "0_603c31b59afd4c0eb25fade694cdb24c_1.json\n",
      "\n",
      "0_6bf71ccc6254498bb6e52e10f45490d8_1.json\n",
      "\n",
      "0_743237a427664f57b35d3bd642572e6d_1.json\n",
      "\n",
      "0_75d343691ca849bdb190d98b11f7edc9_1.json\n",
      "\n",
      "0_8223e703445d414c8f34b45d71a9fe35_1.json\n",
      "\n",
      "0_8d054dcd0a7b487585f77bfee87ff543_1.json\n",
      "\n",
      "0_a48ce3b7dec3442f963db431ff2e4da5_1.json\n",
      "\n",
      "0_bc12f2ee7a2e41f9b463001439e8ae94_1.json\n",
      "\n",
      "0_bcf7c48af48e4ff0bde2b79cf6606216_1.json\n",
      "\n",
      "0_ddb730a7073646d995d0534ada10ceac_1.json\n",
      "\n",
      "It takes 2.5093915462493896 seconds to download 0_ddb730a7073646d995d0534ada10ceac_1.json\n",
      "\n",
      "0_f1ba9f5911b743daae5c728be89b5fb0_1.json\n",
      "\n",
      "0_f1e1947720fb4072a8b325428be98a10_1.json\n",
      "\n",
      "Imported 0_36ecfdb7ea4941c2938e3f91a9003ea0_1.json to the database.\n",
      "Imported 0_ddb730a7073646d995d0534ada10ceac_1.json to the database.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "## Uploads to db without nested structure\r\n",
    "\r\n",
    "# Retrieve list of blobs from designated container\r\n",
    "# Check if blob name is a file name in current directory\r\n",
    "# If no same file name in directory, download the file associated with that blobname\r\n",
    "# If it downloads the file, then it also opens it and imports the data to mongodb\r\n",
    "\r\n",
    "import time\r\n",
    "from azure.storage.blob import ContainerClient\r\n",
    "from azure.storage.blob import BlobServiceClient\r\n",
    "import json\r\n",
    "from pymongo import MongoClient\r\n",
    "\r\n",
    "blob_service_client_instance = BlobServiceClient(account_url=STORAGEACCOUNTURL, credential=STORAGEACCOUNTKEY)\r\n",
    "container = ContainerClient.from_connection_string(conn_str=os.environ.get('AZURE_STORAGE_CONNECTION_STRING'), container_name=\"container2\")\r\n",
    "\r\n",
    "new_files = []\r\n",
    "all_files = []\r\n",
    "\r\n",
    "blob_list = container.list_blobs()\r\n",
    "for blob in blob_list:\r\n",
    "    print(blob.name + '\\n')\r\n",
    "    all_files.append(blob.name)\r\n",
    "    if blob.name not in os.listdir(os.curdir):\r\n",
    "        new_files.append(blob.name)\r\n",
    "        t1=time.time()\r\n",
    "        blob_client_instance = blob_service_client_instance.get_blob_client(\"container2\", blob.name, snapshot=None)\r\n",
    "        with open(blob.name, \"wb\") as my_blob:\r\n",
    "            blob_data = blob_client_instance.download_blob()\r\n",
    "            blob_data.readinto(my_blob)\r\n",
    "        t2=time.time()\r\n",
    "        print((\"It takes %s seconds to download \"+blob.name + '\\n') % (t2 - t1))\r\n",
    "\r\n",
    "### Import new data to mongodb, one file at a time\r\n",
    "\r\n",
    "# Making Connection\r\n",
    "myclient = MongoClient(\"mongodb://localhost:27017/\")\r\n",
    "\r\n",
    "# database\r\n",
    "db = myclient[\"Sensorlab\"]  #update here to switch database\r\n",
    "\r\n",
    "# Create or switch to collection\r\n",
    "Collection = db[\"E4_data\"]  #update here to switch collection\r\n",
    "\r\n",
    "for i in range(len(new_files)):\r\n",
    "    with open(new_files[i]) as f:\r\n",
    "        content = f.readlines()\r\n",
    "    file_data = []\r\n",
    "    for data in content:\r\n",
    "        file_data.append(json.loads(data))\r\n",
    "\r\n",
    "    if isinstance(file_data, list):\r\n",
    "        Collection.insert_many(file_data)\r\n",
    "    else:\r\n",
    "        Collection.insert_one(file_data)\r\n",
    "    print(f\"Imported {new_files[i]} to the database.\")\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0_18fc7328361948c0865df2f0c53aa008_1.json\n",
      "\n",
      "0_2f7120ed65194093a6df6dacd979d706_1.json\n",
      "\n",
      "0_36ecfdb7ea4941c2938e3f91a9003ea0_1.json\n",
      "\n",
      "It takes 3.7836661338806152 seconds to download 0_36ecfdb7ea4941c2938e3f91a9003ea0_1.json\n",
      "\n",
      "0_4862fd0f886945c6b5fa1ed9b391e807_1.json\n",
      "\n",
      "0_5e20c79f9efc42fc9c09b4443a6646de_1.json\n",
      "\n",
      "0_603c31b59afd4c0eb25fade694cdb24c_1.json\n",
      "\n",
      "0_6bf71ccc6254498bb6e52e10f45490d8_1.json\n",
      "\n",
      "0_743237a427664f57b35d3bd642572e6d_1.json\n",
      "\n",
      "0_75d343691ca849bdb190d98b11f7edc9_1.json\n",
      "\n",
      "0_8223e703445d414c8f34b45d71a9fe35_1.json\n",
      "\n",
      "0_8d054dcd0a7b487585f77bfee87ff543_1.json\n",
      "\n",
      "0_a48ce3b7dec3442f963db431ff2e4da5_1.json\n",
      "\n",
      "0_bcf7c48af48e4ff0bde2b79cf6606216_1.json\n",
      "\n",
      "0_ddb730a7073646d995d0534ada10ceac_1.json\n",
      "\n",
      "It takes 3.704059600830078 seconds to download 0_ddb730a7073646d995d0534ada10ceac_1.json\n",
      "\n",
      "0_f1e1947720fb4072a8b325428be98a10_1.json\n",
      "\n",
      "Imported 0_36ecfdb7ea4941c2938e3f91a9003ea0_1.json to the database.\n",
      "Imported 0_ddb730a7073646d995d0534ada10ceac_1.json to the database.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\r\n",
    "os.environ['AZURE_STORAGE_CONNECTION_STRING'] = \"DefaultEndpointsProtocol=https;AccountName=uaholodecksensorlab;AccountKey=GX+Fn1hVo3RDWRGuCxMAVDVFA/maCM2NdGx4Kffv4tWnG6DU8C1NOVH5Rv694e3HVNCmlinkeAKMgnXBvsr7nA==;EndpointSuffix=core.windows.net\"\r\n",
    "\r\n",
    "STORAGEACCOUNTURL= \"https://uaholodecksensorlab.blob.core.windows.net\"\r\n",
    "STORAGEACCOUNTKEY= \"GX+Fn1hVo3RDWRGuCxMAVDVFA/maCM2NdGx4Kffv4tWnG6DU8C1NOVH5Rv694e3HVNCmlinkeAKMgnXBvsr7nA==\""
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "7b4b4feff2f24a0f0a34464dbe537a36fda679851528fb8735cb41fa49dffb2d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}